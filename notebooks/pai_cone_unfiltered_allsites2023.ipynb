{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e541ee59",
   "metadata": {},
   "source": [
    "# PAI for all sites in Berchtesgaden and Bosland based on 30 degree zenith cones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d0302",
   "metadata": {},
   "source": [
    "This notebook generates different vegetation structure values such as PAI at 50 m height from ground from rxp and rdbx files of any scan position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf9121",
   "metadata": {},
   "source": [
    "## Load all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0933997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /mnt/l/lab_nas/projects/weave/data/raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from pylidar_tls_canopy import riegl_io, plant_profile, grid\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import timeit\n",
    "os.chdir(f'/mnt/l/lab_nas/projects/weave/data/raw/')\n",
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ee244",
   "metadata": {},
   "source": [
    "Create csv with all rxp and rdbx files of all scans conducted at TOMST positions (the current code snippet runs very slow at ~1.5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04311a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /mnt/l/lab_nas/projects/weave/data/raw\n",
      "CSV file 'output.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the root directory where your files are stored\n",
    "root_dir = r'/mnt/l/lab_nas/projects/weave/data/raw/'\n",
    "\n",
    "# List to store the extracted path components\n",
    "data = []\n",
    "\n",
    "# Walk through the directory structure\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        # Process only .rxp and .rdbx files\n",
    "        if file.endswith((\".rxp\", \".rdbx\")):\n",
    "            full_path = os.path.join(dirpath, file)\n",
    "\n",
    "            # Split the path into components\n",
    "            path_parts = full_path.split(os.sep)  # OS-independent separator\n",
    "\n",
    "            # Append full path as the last column\n",
    "            path_parts.append(full_path)\n",
    "\n",
    "            # Store in data list\n",
    "            data.append(path_parts)\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_filename = \"output.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Create header dynamically (plus \"Full_Path\" column)\n",
    "    header = [f\"Level_{i}\" for i in range(len(data[0]) - 1)] + [\"Full_Path\"]\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # Write data\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_filename}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e874bb6",
   "metadata": {},
   "source": [
    "Clean the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2b1128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Site  Plot Position Scanner  Year Orientation                File  \\\n",
      "0  BGD     1      C03  vz400i  2023        hori  230709_150710.rdbx   \n",
      "1  BGD     1      C03  vz400i  2023        hori   230709_150710.rxp   \n",
      "2  BGD     1      C03  vz400i  2023        vert  230709_150508.rdbx   \n",
      "3  BGD     1      C03  vz400i  2023        vert   230709_150508.rxp   \n",
      "4  BGD     1      C05  vz400i  2023        hori  230710_092258.rdbx   \n",
      "\n",
      "                                                Path  \n",
      "0  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...  \n",
      "1  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...  \n",
      "2  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...  \n",
      "3  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...  \n",
      "4  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"output.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the first four columns\n",
    "df = df.iloc[:, 8:]\n",
    "\n",
    "# Rename the columns\n",
    "new_column_names = [\"Site\", \"Plot\", \"Position\",\n",
    "                    \"Scanner\", \"Year\", \"Orientation\",\n",
    "                    \"File\", \"Path\"]\n",
    "df.columns = new_column_names[: len(df.columns)]\n",
    "\n",
    "# Save the modified CSV file (optional)\n",
    "df.to_csv(\"output_cleaned.csv\", index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21e3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths(data):\n",
    "    try:\n",
    "        # Group by 'folder' and aggregate paths\n",
    "        grouped = data.groupby(['Site',\n",
    "                              'Plot',\n",
    "                              'Position',\n",
    "                              'Year']).agg({\n",
    "            'Path': list\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Assign paths to rdbx and rxp files\n",
    "        grouped['rdb_v'] = grouped['Path'].apply(lambda x: next((f for f in x if f.endswith(\".rdbx\") and '/vert/' in f), None))\n",
    "        grouped['rxp_v'] = grouped['Path'].apply(lambda x: next((f for f in x if f.endswith(\".rxp\") and '/vert/' in f), None))\n",
    "        grouped['dat_v'] = \"/mnt/l/lab_nas/projects/weave/data/tls/matrices/ScanPosDummy.DAT\"\n",
    "        grouped['rdb_h'] = grouped['Path'].apply(lambda x: next((f for f in x if f.endswith(\".rdbx\") and '/hori/' in f), None))\n",
    "        grouped['rxp_h'] = grouped['Path'].apply(lambda x: next((f for f in x if f.endswith(\".rxp\") and '/hori/' in f), None))\n",
    "        grouped['dat_h'] = \"/mnt/l/lab_nas/projects/weave/data/tls/matrices/ScanPosDummy.DAT\"\n",
    "        \n",
    "        return grouped[['rdb_v', 'rxp_v', 'dat_v',\n",
    "                        'rdb_h', 'rxp_h', 'dat_h']]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data '{data}': {e}\")\n",
    "        return [None, None, None, None, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcbafcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/l/lab_nas/projects/weave/data/raw\n",
      "                                               rdb_v  \\\n",
      "0  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "1  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "2  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "3  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "4  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "\n",
      "                                               rxp_v  \\\n",
      "0  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "1  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "2  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "3  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "4  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "\n",
      "                                               dat_v  \\\n",
      "0  /mnt/l/lab_nas/projects/weave/data/tls/matrice...   \n",
      "1  /mnt/l/lab_nas/projects/weave/data/tls/matrice...   \n",
      "2  /mnt/l/lab_nas/projects/weave/data/tls/matrice...   \n",
      "3  /mnt/l/lab_nas/projects/weave/data/tls/matrice...   \n",
      "4  /mnt/l/lab_nas/projects/weave/data/tls/matrice...   \n",
      "\n",
      "                                               rdb_h  \\\n",
      "0  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "1  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "2  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "3  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "4  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "\n",
      "                                               rxp_h  \\\n",
      "0  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "1  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "2  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "3  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "4  /mnt/l/lab_nas/projects/weave/data/raw/BGD/001...   \n",
      "\n",
      "                                               dat_h  \n",
      "0  /mnt/l/lab_nas/projects/weave/data/tls/matrice...  \n",
      "1  /mnt/l/lab_nas/projects/weave/data/tls/matrice...  \n",
      "2  /mnt/l/lab_nas/projects/weave/data/tls/matrice...  \n",
      "3  /mnt/l/lab_nas/projects/weave/data/tls/matrice...  \n",
      "4  /mnt/l/lab_nas/projects/weave/data/tls/matrice...  \n",
      "250\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "file_list = get_filepaths(df).apply(pd.Series)\n",
    "print(file_list.head())\n",
    "print(len(file_list))\n",
    "file_list.to_excel('scan_info.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3e88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coneprofiles(scans):\n",
    "    vert_rdbx_fn = scans['rdb_v']\n",
    "    vert_rxp_fn = scans['rxp_v']\n",
    "    vert_transform_fn = scans['dat_v']\n",
    "\n",
    "    hori_rdbx_fn = scans['rdb_h']\n",
    "    hori_rxp_fn = scans['rxp_h']\n",
    "    hori_transform_fn = scans['dat_h']\n",
    "    print(\"done1\")\n",
    "    # Determine the origin coordinates to use\n",
    "    transform_matrix = riegl_io.read_transform_file(vert_transform_fn)\n",
    "    x0,y0,z0,_ = transform_matrix[3,:]\n",
    "\n",
    "    grid_extent = 60\n",
    "    grid_resolution = 1\n",
    "    grid_origin = [x0,y0]\n",
    "    \n",
    "\n",
    "    # If using RXP files only as input, set rxp to True:\n",
    "    x,y,z,r = plant_profile.get_min_z_grid([vert_rdbx_fn], \n",
    "                                           [vert_transform_fn], \n",
    "                                        grid_extent, grid_resolution, grid_origin=grid_origin,\n",
    "                                        rxp=False)\n",
    "    \n",
    "    # Optional weighting of points by 1 / range\n",
    "    planefit = plant_profile.plane_fit_hubers(x, y, z, w=1/r)\n",
    "    #planefit['Summary']\n",
    "    \n",
    "    print(\"done2\")\n",
    "    # If the ground plane is not defined then set ground_plane to None\n",
    "    # and use the sensor_height argument when adding scan positions\n",
    "    vpp = plant_profile.Jupp2009(hres=0.5, zres=30, ares=90, \n",
    "                                min_z=0, max_z=30, min_h=0, max_h=50,\n",
    "                                ground_plane=planefit['Parameters'])\n",
    "\n",
    "    # If using RXP files only as input, set rdbx_file to None (the default)\n",
    "    query_str = ['reflectance > -20']\n",
    "    print(\"done3\")\n",
    "\n",
    "    # If using RXP files only as input, set rdbx_file to None (the default)\n",
    "    query_str = ['reflectance > -20']\n",
    "    vpp.add_riegl_scan_position(hori_rxp_fn, hori_transform_fn, sensor_height=1.8,\n",
    "        rdbx_file=hori_rdbx_fn, method='WEIGHTED', min_zenith=0, max_zenith=30,\n",
    "        query_str=query_str)\n",
    "    \n",
    "    vpp.get_pgap_theta_z(min_azimuth=0, max_azimuth=360)\n",
    "    pgap_cone = vpp.pgap_theta_z\n",
    "    #pai_weighted_cone = vpp.calcSolidAnglePlantProfiles()\n",
    "    #pai_linear_cone = vpp.calcLinearPlantProfiles()\n",
    "    #weighted_pai = vpp.calcSolidAnglePlantProfiles()\n",
    "    #linear_pai = vpp.calcLinearPlantProfiles()\n",
    "\n",
    "    #hinge_pavd = vpp.get_pavd(hinge_pai)\n",
    "    #linear_pavd = vpp.get_pavd(linear_pai)\n",
    "    #weighted_pavd = vpp.get_pavd(weighted_pai)\n",
    "    \n",
    "    print(\"done4\")\n",
    "\n",
    "    #weighted_pai= pd.DataFrame(weighted_pai)\n",
    "    #weighted_pai.to_csv(str(up)+'pai'+'.csv', sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "    #weighted_pavd= pd.DataFrame(weighted_pavd)\n",
    "    #weighted_pavd.to_csv(str(up)+'pavd'+'.csv', sep=',', index=False, encoding='utf-8')\n",
    "    \n",
    "    print(pgap_cone)\n",
    "    return [pgap_cone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7650a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n"
     ]
    }
   ],
   "source": [
    "bgd001_cones = file_list.head(5).apply(get_coneprofiles, axis=1)\n",
    "bgd001_cones.to_csv('pgap_cone_allscans_unfiltered.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylidar-tls-canopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
